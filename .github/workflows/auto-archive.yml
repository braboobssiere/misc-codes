name: Scheduled Auto-Archive

on:
  workflow_dispatch:
  schedule:
    - cron: '35 * * * *'  # Run at 35 minutes past every hour

jobs:
  process_feed_and_download:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4


      - name: Setup Environment
        run: |
          sudo apt-get update
          PACKAGES="ffmpeg python3-pip wireguard-tools jq curl xmlstarlet"
          sudo apt-get install -y $PACKAGES
          python3 -m pip install --upgrade pip --pre yt-dlp[default,curl-cffi]

      - name: Parse Atom Feed
        id: feed-parser
        run: |
          FEED_URL="https://raw.githubusercontent.com/braboobssiere/holedex-song-list/main/feeds/holodex.atom"
          CURRENT_TS=$(date +%s)
          LATEST_URL=""
          LATEST_TS=0
          
          while IFS= read -r entry; do
            URL=$(echo "$entry" | xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
              -t -v "//atom:link[@rel='alternate']/@href" 2>/dev/null | tr -d '\n')
            
            TITLE=$(echo "$entry" | xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
              -t -v "//atom:title" 2>/dev/null | tr -d '\n')
            
            SUMMARY=$(echo "$entry" | xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
              -t -v "//atom:summary" 2>/dev/null | tr -d '\n')

            TS=$(echo "$SUMMARY" | grep -oP 't:\K\d{10}')

            echo "Processing entry:"
            echo "URL: $URL | Title: $TITLE | TS: $TS"

            if [[ -n "$URL" && -n "$TS" ]] && \
               [[ "${TITLE,,}" == *"unarchive"* ]] && \
               [[ "$URL" == *"youtu.be/"* ]] && \
               [[ $CURRENT_TS -ge $TS && $CURRENT_TS -le $((TS + 3540)) ]]; then
              
              if [[ $TS -gt $LATEST_TS ]]; then
                LATEST_URL="$URL"
                LATEST_TS=$TS
                echo "New valid candidate: $URL (TS: $TS)"
              fi
            fi
          done < <(curl -sL "$FEED_URL" | xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
            -t -m "//atom:entry" -c "." -n 2>/dev/null)

          if [[ -n "$LATEST_URL" ]]; then
            echo "url=$LATEST_URL" >> $GITHUB_OUTPUT
            echo "should_process=true" >> $GITHUB_OUTPUT
            echo "::notice::Found valid URL: $LATEST_URL"
          else
            echo "::notice::No valid entries found"
            echo "should_process=false" >> $GITHUB_OUTPUT
          fi

      - name: VPN Setup (TradeWar)
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        env:
          TradeWar_CONFIG: ${{ secrets.WIREGUARD_TRADEWAR }}
        run: |
          sudo mkdir -p /etc/wireguard/
          echo "$TradeWar_CONFIG" | sudo tee /etc/wireguard/wg0.conf > /dev/null
          sudo chmod 600 /etc/wireguard/wg0.conf

          for i in {1..5}; do
              sudo wg-quick up wg0
              sleep 1 
              if sudo wg show wg0 >/dev/null 2>&1; then
                  echo "VPN connected successfully on attempt $i"
                  break
              else
                  echo "VPN connection failed (attempt $i/5)"
                  sudo wg-quick down wg0 >/dev/null 2>&1
                  [ $i -lt 5 ] && sleep 1
              fi
          done

          if ! sudo wg show wg0 >/dev/null 2>&1; then
              echo "::error::VPN failed to connect after 5 attempts"
              exit 1
          fi

      - name: Download and Process Video
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        continue-on-error: true
        run: |
          mkdir -p output
          URL="${{ steps.feed-parser.outputs.url }}"
          
          yt-dlp -i --no-progress \
            -S \"+res:1080,+vcodec:av01\" --windows-filenames \
            -o \"output/%(title).170B [%(id)s] (%(resolution)s).%(ext)s\" \
            --live-from-start --embed-metadata ${URL}

      - name: VPN Cleanup
        if: ${{ always() && steps.feed-parser.outputs.should_process == 'true' }}
        run: |
          sudo wg-quick down wg0 || true

      - name: Upload Artifact
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: downloaded-video
          path: output
          compression-level: 1
          if-no-files-found: error

      - name: Upload Files to Cloud Storage
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        run: |
          UPLOAD_URL="https://upload.gofile.io/uploadfile"
          UPLOAD_LINKS=""
          guest_token=""
          folder_id=""

          upload_file() {
            local file=$1
            shift
            local extra_args=("$@")

            RESPONSE=$(curl -s -X POST -F "file=@\"$file\"" "${extra_args[@]}" "$UPLOAD_URL")
            STATUS=$(echo "$RESPONSE" | jq -r '.status')
            if [ "$STATUS" != "ok" ]; then
              ERROR=$(echo "$RESPONSE" | jq -r '.data // .status')
              echo "::error::Upload failed for $file: $ERROR"
              exit 1
            fi
            echo "$RESPONSE"
          }

          for file in output/*; do
            echo "Uploading $(basename "$file")..."
            extra_args=()
            if [ -n "$guest_token" ] && [ "$guest_token" != "null" ] && 
               [ -n "$folder_id" ] && [ "$folder_id" != "null" ]; then
              echo "::add-mask::$guest_token"
              echo "::add-mask::$folder_id"
              extra_args=(-H "Authorization: Bearer $guest_token" -F "folderId=$folder_id")
            fi

            RESPONSE=$(upload_file "$file" "${extra_args[@]}")

            if [ -z "$guest_token" ]; then
              guest_token=$(echo "$RESPONSE" | jq -r '.data.guestToken')
              echo "::add-mask::$guest_token"
            fi
            if [ -z "$folder_id" ]; then
              folder_id=$(echo "$RESPONSE" | jq -r '.data.parentFolder')
              echo "::add-mask::$folder_id"
            fi

            LINK=$(echo "$RESPONSE" | jq -r '.data.downloadPage')
            UPLOAD_LINKS+="- [$(basename "$file")]($LINK)\n"
          done

          FILE_COUNT=$(echo -e "$UPLOAD_LINKS" | grep -c '^-')
          SUMMARY="### 📁 Upload Results\n**Files uploaded:** $FILE_COUNT"

          # Append the upload summary to GitHub Step Summary
          echo -e "$SUMMARY\n\n$UPLOAD_LINKS" >> $GITHUB_STEP_SUMMARY
          echo "links=$(echo -e "$UPLOAD_LINKS" | base64 -w 0)" >> $GITHUB_OUTPUT
