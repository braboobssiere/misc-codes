name: Scheduled Archive Download

on:
  workflow_dispatch:
  schedule:
    - cron: '35 * * * *'  # Run at 35 minutes past every hour

jobs:
  process_feed_and_download:
    runs-on: ubuntu-latest
    env:
      VPN_LOCATION: 'TradeWar'
      RESOLUTION: '1080p'
      COOKIES: 'false'
      ADDITIONAL_ARGS: ''
      UPLOAD_TO_CLOUD: 'true'

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Check for Concurrent Runs
        id: concurrency-check
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Get current workflow information
          CURRENT_RUN_ID=${{ github.run_id }}
          WORKFLOW_NAME="${{ github.workflow }}"

          # Get active workflow runs
          RESPONSE=$(curl -s \
            -H "Authorization: Bearer $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs?workflow=$WORKFLOW_NAME&status=in_progress&status=queued")

          # Count runs excluding current
          RUN_COUNT=$(echo "$RESPONSE" | jq "[.workflow_runs[] | select(.id != $CURRENT_RUN_ID)] | length")

          if [ "$RUN_COUNT" -gt 0 ]; then
            echo "::notice::Another active workflow detected (count: $RUN_COUNT)"
            echo "should_process=false" >> $GITHUB_OUTPUT
          else
            echo "should_process=true" >> $GITHUB_OUTPUT
          fi

      - name: Install XMLStarlet
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' }}
        run: sudo apt-get install -y xmlstarlet

      - name: Parse Atom Feed
        id: feed-parser
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' }}
        run: |
          FEED_URL="https://raw.githubusercontent.com/braboobssiere/holedex-song-list/main/feeds/holodex.atom"
          CURRENT_TS=$(date +%s)
          
          VALID_ENTRIES=$(curl -sL "$FEED_URL" | xmlstarlet sel -t -m "//feed/entry" -v "
            concat(
              substring-before(link[@rel='alternate']/@href, '?'), '|',
              title, '|',
              translate(summary, '&lt;t:', '|'), '|'
            )" -n)

          LATEST_URL=""
          LATEST_TS=0

          while IFS= read -r entry; do
            IFS='|' read -ra PARTS <<< "$entry"
            URL="${PARTS[0]}"
            TITLE="${PARTS[1]}"
            TS=$(echo "${PARTS[3]}" | grep -oE '[0-9]{10}')

            if [[ -n "$URL" && -n "$TS" ]] && \
               [[ "${TITLE,,}" == *"unarchive"* ]] && \
               [[ $CURRENT_TS -ge $TS && $CURRENT_TS -le $((TS + 3540)) ]]; then
              
              if [[ $TS -gt $LATEST_TS ]]; then
                LATEST_URL="$URL"
                LATEST_TS=$TS
              fi
            fi
          done <<< "$VALID_ENTRIES"

          if [[ -n "$LATEST_URL" ]]; then
            echo "url=$LATEST_URL" >> $GITHUB_OUTPUT
            echo "feed_should_process=true" >> $GITHUB_OUTPUT
          else
            echo "::notice::No valid entries found"
            echo "feed_should_process=false" >> $GITHUB_OUTPUT
          fi

      - name: Setup Environment
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' && steps.feed-parser.outputs.feed_should_process == 'true' }}
        run: |
          sudo apt-get update
          PACKAGES="ffmpeg python3-pip wireguard-tools jq curl"
          sudo apt-get install -y $PACKAGES
          python3 -m pip install --upgrade pip --pre yt-dlp[default,curl-cffi]

      - name: VPN Setup (TradeWar)
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' && steps.feed-parser.outputs.feed_should_process == 'true' }}
        env:
          TradeWar_CONFIG: ${{ secrets.WIREGUARD_TRADEWAR }}
        run: |
          sudo mkdir -p /etc/wireguard/
          echo "$TradeWar_CONFIG" | sudo tee /etc/wireguard/wg0.conf > /dev/null
          sudo chmod 600 /etc/wireguard/wg0.conf

          for i in {1..5}; do
              sudo wg-quick up wg0
              sleep 1 
              if sudo wg show wg0 >/dev/null 2>&1; then
                  echo "VPN connected successfully on attempt $i"
                  break
              else
                  echo "VPN connection failed (attempt $i/5)"
                  sudo wg-quick down wg0 >/dev/null 2>&1
                  [ $i -lt 5 ] && sleep 1
              fi
          done

          if ! sudo wg show wg0 >/dev/null 2>&1; then
              echo "::error::VPN failed to connect after 5 attempts"
              exit 1
          fi

      - name: Download and Process Video
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' && steps.feed-parser.outputs.feed_should_process == 'true' }}
        run: |
          mkdir -p output
          URL="${{ steps.feed-parser.outputs.url }}"
          
          yt-dlp -i --no-progress \
            -S "+res:1080,+vcodec:av01" --windows-filenames \
            -o "output/%(title).170B [%(id)s] (%(resolution)s).%(ext)s" \
            --embed-metadata --live-from-start "$URL"

      - name: VPN Cleanup
        if: ${{ always() && steps.concurrency-check.outputs.should_process == 'true' && steps.feed-parser.outputs.feed_should_process == 'true' }}
        run: |
          sudo wg-quick down wg0 || true

      - name: Upload Artifact
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' && steps.feed-parser.outputs.feed_should_process == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: downloaded-video
          path: output
          compression-level: 1
          if-no-files-found: error

      - name: Upload Files to Cloud Storage
        if: ${{ steps.concurrency-check.outputs.should_process == 'true' && steps.feed-parser.outputs.feed_should_process == 'true' }}
        run: |
          UPLOAD_URL="https://upload.gofile.io/uploadfile"
          UPLOAD_LINKS=""
          guest_token=""
          folder_id=""

          upload_file() {
            local file=$1
            shift
            local extra_args=("$@")

            RESPONSE=$(curl -s -X POST -F "file=@\"$file\"" "${extra_args[@]}" "$UPLOAD_URL")
            STATUS=$(echo "$RESPONSE" | jq -r '.status')
            if [ "$STATUS" != "ok" ]; then
              ERROR=$(echo "$RESPONSE" | jq -r '.data // .status')
              echo "::error::Upload failed for $file: $ERROR"
              exit 1
            fi
            echo "$RESPONSE"
          }

          for file in output/*; do
            echo "Uploading $(basename "$file")..."
            extra_args=()
            if [ -n "$guest_token" ] && [ "$guest_token" != "null" ] && 
               [ -n "$folder_id" ] && [ "$folder_id" != "null" ]; then
              echo "::add-mask::$guest_token"
              echo "::add-mask::$folder_id"
              extra_args=(-H "Authorization: Bearer $guest_token" -F "folderId=$folder_id")
            fi

            RESPONSE=$(upload_file "$file" "${extra_args[@]}")

            if [ -z "$guest_token" ]; then
              guest_token=$(echo "$RESPONSE" | jq -r '.data.guestToken')
              echo "::add-mask::$guest_token"
            fi
            if [ -z "$folder_id" ]; then
              folder_id=$(echo "$RESPONSE" | jq -r '.data.parentFolder')
              echo "::add-mask::$folder_id"
            fi

            LINK=$(echo "$RESPONSE" | jq -r '.data.downloadPage')
            UPLOAD_LINKS+="- [$(basename "$file")]($LINK)\n"
          done

          FILE_COUNT=$(echo -e "$UPLOAD_LINKS" | grep -c '^-')
          SUMMARY="### 📁 Upload Results\n**Files uploaded:** $FILE_COUNT"

          # Append the upload summary to GitHub Step Summary
          echo -e "$SUMMARY\n\n$UPLOAD_LINKS" >> $GITHUB_STEP_SUMMARY
          echo "links=$(echo -e "$UPLOAD_LINKS" | base64 -w 0)" >> $GITHUB_OUTPUT
