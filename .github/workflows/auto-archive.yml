name: Auto-Download Video

on:
  workflow_dispatch:
  # schedule: # use cron-job.org instead
  #   - cron: '35 * * * *'

concurrency:
  group: Auto-Download Video
  cancel-in-progress: false

jobs:
  check-feed:
    name: Check Feed for Valid Entries
    runs-on: ubuntu-latest
    outputs:
      should_process: ${{ steps.feed-parser.outputs.should_process }}
      url: ${{ steps.feed-parser.outputs.url }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5.5.0
        with:
          python-version: '3.11'

      - name: Install parsing dependencies
        run: pip install requests

      - name: Parse and Validate Feed
        id: feed-parser
        run: |
          import xml.etree.ElementTree as ET
          import requests
          import re
          from datetime import datetime, timedelta, UTC
          import os
          import json

          feed_url = "https://raw.githubusercontent.com/braboobssiere/holedex-song-list/main/feeds/holodex.atom"
          response = requests.get(feed_url)
          root = ET.fromstring(response.content)

          ns = {'atom': 'http://www.w3.org/2005/Atom'}
          current_time = datetime.now(UTC)
          time_threshold = current_time - timedelta(minutes=60)
          matched_entries = []

          for entry in root.findall('atom:entry', ns):
              title = entry.find('atom:title', ns).text or ''
              if 'unarchive' not in title.lower():
                  continue

              if not (summary := entry.find('atom:summary', ns).text):
                  continue

              if not (timestamp_match := re.search(r't:(\d+)', summary)):
                  continue

              entry_time = datetime.fromtimestamp(
                  int(timestamp_match.group(1)), 
                  tz=UTC
              )

              if time_threshold <= entry_time <= current_time:
                  link = entry.find("atom:link[@rel='alternate']", ns).attrib['href']
                  matched_entries.append((entry_time, link))

          # Sort by newest first and keep up to 4 entries
          matched_entries.sort(reverse=True, key=lambda x: x[0])
          matched_entries = matched_entries[:4]

          output_path = os.environ['GITHUB_OUTPUT']
          with open(output_path, 'a') as f:
              if matched_entries:
                # Create list of entries with indexes for matrix strategy
                entries = [{"url": e[1], "index": i} for i, e in enumerate(matched_entries)]
                f.write(f'should_process=true\nurls={json.dumps(entries)}\n')
              else:
                f.write('should_process=false\n')
                exit 78
        shell: python
        env:
          TZ: UTC

  process-video:
    name: Process and Upload Video
    needs: check-feed
    if: ${{ needs.check-feed.outputs.should_process == 'true' }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        entry: ${{ fromJson(needs.check-feed.outputs.urls) }}
      max-parallel: 4

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Heavy Dependencies
        run: |
          sudo apt-get update
          PACKAGES="ffmpeg python3-pip wireguard-tools jq curl"
          sudo apt-get install -y $PACKAGES
          python3 -m pip install --upgrade pip --pre yt-dlp[default,curl-cffi]

      - name: VPN Setup (TradeWar)
        env:
          TradeWar_CONFIG: ${{ secrets.WIREGUARD_TRADEWAR }}
        run: |
          sudo mkdir -p /etc/wireguard/
          echo "$TradeWar_CONFIG" | sudo tee /etc/wireguard/wg0.conf > /dev/null
          sudo chmod 600 /etc/wireguard/wg0.conf

          for i in {1..5}; do
              sudo wg-quick up wg0
              sleep 1 
              if sudo wg show wg0 >/dev/null 2>&1; then
                  echo "VPN connected successfully on attempt $i"
                  break
              else
                  echo "VPN connection failed (attempt $i/5)"
                  sudo wg-quick down wg0 >/dev/null 2>&1
                  [ $i -lt 5 ] && sleep 1
              fi
          done

          if ! sudo wg show wg0 >/dev/null 2>&1; then
              echo "::error::VPN failed to connect after 5 attempts"
              exit 1
          fi

      - name: Download and Process Video
        continue-on-error: true
        run: |
          OUTPUT_DIR="output/${{ matrix.entry.index }}"
          mkdir -p "${OUTPUT_DIR}"
          URL="${{ matrix.entry.url }}"
          
          {
          echo "=== Processing URL ${{ matrix.entry.url }} ==="
          yt-dlp -i --no-progress -S "+res:1080,+vcodec:av01" \
            --windows-filenames --live-from-start --embed-metadata \
            -o "${OUTPUT_DIR}/%(title).170B [%(id)s] (%(resolution)s).%(ext)s" \
            "${URL}"
          } > "${OUTPUT_DIR}/logs.txt" 2>&1

      - name: VPN Cleanup
        if: ${{ always() }}
        run: |
          sudo wg-quick down wg0 || true

      - name: Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: downloaded-video
          path: output
          compression-level: 1
          if-no-files-found: error

      - name: Upload Files to Cloud Storage
        run: |
          UPLOAD_URL="https://upload.gofile.io/uploadfile"
          UPLOAD_LINKS=""
          guest_token=""
          folder_id=""
          OUTPUT_DIR="output/${{ matrix.entry.index }}"

          upload_file() {
            local file=$1
            shift
            local extra_args=("$@")

            RESPONSE=$(curl -s -X POST -F "file=@\"$file\"" "${extra_args[@]}" "$UPLOAD_URL")
            STATUS=$(echo "$RESPONSE" | jq -r '.status')
            if [ "$STATUS" != "ok" ]; then
              ERROR=$(echo "$RESPONSE" | jq -r '.data // .status')
              echo "::error::Upload failed for $file: $ERROR"
              exit 1
            fi
            echo "$RESPONSE"
          }

          for file in "${OUTPUT_DIR}"/*; do
            echo "Uploading $(basename "$file")..."
            extra_args=()
            if [ -n "$guest_token" ] && [ "$guest_token" != "null" ] && 
               [ -n "$folder_id" ] && [ "$folder_id" != "null" ]; then
              echo "guest_token=***" >> $GITHUB_OUTPUT
              echo "folder_id=***" >> $GITHUB_OUTPUT
              extra_args=(-H "Authorization: Bearer $guest_token" -F "folderId=$folder_id")
            fi

            RESPONSE=$(upload_file "$file" "${extra_args[@]}")

            if [ -z "$guest_token" ]; then
              guest_token=$(echo "$RESPONSE" | jq -r '.data.guestToken')
              echo "guest_token=$guest_token" >> $GITHUB_OUTPUT
            fi
            if [ -z "$folder_id" ]; then
              folder_id=$(echo "$RESPONSE" | jq -r '.data.parentFolder')
              echo "folder_id=$folder_id" >> $GITHUB_OUTPUT
            fi

            LINK=$(echo "$RESPONSE" | jq -r '.data.downloadPage')
            UPLOAD_LINKS+="- [$(basename "$file")]($LINK)\n"
          done

          FILE_COUNT=$(echo -e "$UPLOAD_LINKS" | grep -c '^-')
          SUMMARY="### 📁 Upload Results\n**Files uploaded:** $FILE_COUNT"

          echo -e "$SUMMARY\n\n$UPLOAD_LINKS" >> $GITHUB_STEP_SUMMARY
          echo "links=$(echo -e "$UPLOAD_LINKS" | base64 -w 0)" >> $GITHUB_OUTPUT
