name: Scheduled Auto-Archive

on:
  workflow_dispatch:
  schedule:
    - cron: '35 * * * *'  # Run at 35 minutes past every hour

jobs:
  process_feed_and_download:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4


      - name: Setup Environment
        run: |
          sudo apt-get update
          PACKAGES="ffmpeg python3-pip wireguard-tools jq curl xmlstarlet"
          sudo apt-get install -y $PACKAGES
          python3 -m pip install --upgrade pip --pre yt-dlp[default,curl-cffi]

      - name: Parse Atom Feed
        id: feed-parser
        run: |
          FEED_URL="https://raw.githubusercontent.com/braboobssiere/holedex-song-list/main/feeds/holodex.atom"
          CURRENT_TS=$(date +%s)
          
          # Process feed with XMLStarlet
          VALID_ENTRIES=$(curl -sL "$FEED_URL" | xmlstarlet sel -t -m "//feed/entry" -v "
            concat(
              substring-before(link[@rel='alternate']/@href, '?'), '|',
              title, '|',
              translate(summary, '&lt;t:', '|'), '|'
            )" -n)

          LATEST_URL=""
          LATEST_TS=0

          # Parse all entries
          while IFS= read -r entry; do
            IFS='|' read -ra PARTS <<< "$entry"
            URL="${PARTS[0]}"
            TITLE="${PARTS[1]}"
            TS=$(echo "${PARTS[3]}" | grep -oE '[0-9]{10}')

            # Validation checks
            if [[ -n "$URL" && -n "$TS" ]] && \
               [[ "${TITLE,,}" == *"unarchive"* ]] && \
               [[ $CURRENT_TS -ge $TS && $CURRENT_TS -le $((TS + 3540)) ]]; then
              
              # Keep only the latest valid entry
              if [[ $TS -gt $LATEST_TS ]]; then
                LATEST_URL="$URL"
                LATEST_TS=$TS
              fi
            fi
          done <<< "$VALID_ENTRIES"

          if [[ -n "$LATEST_URL" ]]; then
            echo "url=$LATEST_URL" >> $GITHUB_OUTPUT
            echo "should_process=true" >> $GITHUB_OUTPUT
            echo "::notice::Found valid URL: $LATEST_URL"
          else
            echo "::notice::No valid entries found"
            echo "should_process=false" >> $GITHUB_OUTPUT
          fi

      - name: VPN Setup (TradeWar)
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        env:
          TradeWar_CONFIG: ${{ secrets.WIREGUARD_TRADEWAR }}
        run: |
          sudo mkdir -p /etc/wireguard/
          echo "$TradeWar_CONFIG" | sudo tee /etc/wireguard/wg0.conf > /dev/null
          sudo chmod 600 /etc/wireguard/wg0.conf

          for i in {1..5}; do
              sudo wg-quick up wg0
              sleep 1 
              if sudo wg show wg0 >/dev/null 2>&1; then
                  echo "VPN connected successfully on attempt $i"
                  break
              else
                  echo "VPN connection failed (attempt $i/5)"
                  sudo wg-quick down wg0 >/dev/null 2>&1
                  [ $i -lt 5 ] && sleep 1
              fi
          done

          if ! sudo wg show wg0 >/dev/null 2>&1; then
              echo "::error::VPN failed to connect after 5 attempts"
              exit 1
          fi

      - name: Download and Process Video
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        continue-on-error: true
        run: |
          mkdir -p output
          URL="${{ steps.feed-parser.outputs.url }}"
          
          yt-dlp -i --no-progress \
            -S \"+res:1080,+vcodec:av01\" --windows-filenames \
            -o \"output/%(title).170B [%(id)s] (%(resolution)s).%(ext)s\" \
            --live-from-start --embed-metadata ${URL}

      - name: VPN Cleanup
        if: ${{ always() && steps.feed-parser.outputs.should_process == 'true' }}
        run: |
          sudo wg-quick down wg0 || true

      - name: Upload Artifact
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: downloaded-video
          path: output
          compression-level: 1
          if-no-files-found: error

      - name: Upload Files to Cloud Storage
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        run: |
          UPLOAD_URL="https://upload.gofile.io/uploadfile"
          UPLOAD_LINKS=""
          guest_token=""
          folder_id=""

          upload_file() {
            local file=$1
            shift
            local extra_args=("$@")

            RESPONSE=$(curl -s -X POST -F "file=@\"$file\"" "${extra_args[@]}" "$UPLOAD_URL")
            STATUS=$(echo "$RESPONSE" | jq -r '.status')
            if [ "$STATUS" != "ok" ]; then
              ERROR=$(echo "$RESPONSE" | jq -r '.data // .status')
              echo "::error::Upload failed for $file: $ERROR"
              exit 1
            fi
            echo "$RESPONSE"
          }

          for file in output/*; do
            echo "Uploading $(basename "$file")..."
            extra_args=()
            if [ -n "$guest_token" ] && [ "$guest_token" != "null" ] && 
               [ -n "$folder_id" ] && [ "$folder_id" != "null" ]; then
              echo "::add-mask::$guest_token"
              echo "::add-mask::$folder_id"
              extra_args=(-H "Authorization: Bearer $guest_token" -F "folderId=$folder_id")
            fi

            RESPONSE=$(upload_file "$file" "${extra_args[@]}")

            if [ -z "$guest_token" ]; then
              guest_token=$(echo "$RESPONSE" | jq -r '.data.guestToken')
              echo "::add-mask::$guest_token"
            fi
            if [ -z "$folder_id" ]; then
              folder_id=$(echo "$RESPONSE" | jq -r '.data.parentFolder')
              echo "::add-mask::$folder_id"
            fi

            LINK=$(echo "$RESPONSE" | jq -r '.data.downloadPage')
            UPLOAD_LINKS+="- [$(basename "$file")]($LINK)\n"
          done

          FILE_COUNT=$(echo -e "$UPLOAD_LINKS" | grep -c '^-')
          SUMMARY="### 📁 Upload Results\n**Files uploaded:** $FILE_COUNT"

          # Append the upload summary to GitHub Step Summary
          echo -e "$SUMMARY\n\n$UPLOAD_LINKS" >> $GITHUB_STEP_SUMMARY
          echo "links=$(echo -e "$UPLOAD_LINKS" | base64 -w 0)" >> $GITHUB_OUTPUT
