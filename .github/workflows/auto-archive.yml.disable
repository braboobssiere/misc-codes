name: Scheduled Auto-Archive

on:
  workflow_dispatch:
  schedule:
    - cron: '35 * * * *'  # Run at 35 minutes past every hour

jobs:
  process_feed_and_download:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4


      - name: Setup Environment
        run: |
          sudo apt-get update
          PACKAGES="ffmpeg python3-pip wireguard-tools jq curl xmlstarlet"
          sudo apt-get install -y $PACKAGES
          python3 -m pip install --upgrade pip --pre yt-dlp[default,curl-cffi]
      - name: Parse Atom Feed
        id: feed-parser
        run: |
          FEED_URL="https://raw.githubusercontent.com/braboobssiere/holedex-song-list/main/feeds/holodex.atom"
          CURRENT_TS=$(date +%s)
          LATEST_URL=""
          LATEST_TS=0

          # Add error handling
          set -euo pipefail

          # Process entries with proper XML handling
          while IFS= read -r entry; do
            # Create temporary file for XML fragment
            TEMP_XML=$(mktemp)
            echo "$entry" > "$TEMP_XML"

            # Extract components with error suppression
            URL=$(xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
              -t -v "/atom:entry/atom:link[@rel='alternate']/@href" "$TEMP_XML" 2>/dev/null || true)
            
            TITLE=$(xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
              -t -v "/atom:entry/atom:title" "$TEMP_XML" 2>/dev/null || true)
            
            SUMMARY=$(xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
              -t -v "/atom:entry/atom:summary" "$TEMP_XML" 2>/dev/null || true)

            # Clean up temp file
            rm -f "$TEMP_XML"

            # Improved timestamp extraction
            TS=$(echo "$SUMMARY" | grep -oP 't:\K\d{10}' || true)

            echo "Processing entry:"
            echo "URL: '$URL' | Title: '$TITLE' | TS: '$TS'"

            # Validation checks with error tolerance
            if [[ -n "$URL" && -n "$TS" ]] && \
               [[ "${TITLE,,}" == *"unarchive"* ]] && \
               [[ "$URL" == *"youtu.be/"* ]]; then
              
              # Time window check
              if (( CURRENT_TS >= TS && CURRENT_TS <= TS + 3540 )); then
                echo "Valid time window: $TS -> $((TS + 3540))"
                if (( TS > LATEST_TS )); then
                  LATEST_URL="$URL"
                  LATEST_TS=$TS
                  echo "New valid candidate: $URL (TS: $TS)"
                fi
              else
                echo "Time window expired: $CURRENT_TS not in [$TS, $((TS + 3540))]"
              fi
            else
              echo "Entry failed validation checks"
            fi
          done < <(curl -sL "$FEED_URL" | xmlstarlet sel -N atom="http://www.w3.org/2005/Atom" \
            -t -m "/atom:feed/atom:entry" -c "." -n 2>/dev/null)

          # Final output
          if [[ -n "$LATEST_URL" ]]; then
            echo "url=$LATEST_URL" >> $GITHUB_OUTPUT
            echo "should_process=true" >> $GITHUB_OUTPUT
            echo "::notice::Found valid URL: $LATEST_URL"
          else
            echo "::notice::No valid entries found"
            echo "should_process=false" >> $GITHUB_OUTPUT
          fi


      - name: VPN Setup (TradeWar)
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        env:
          TradeWar_CONFIG: ${{ secrets.WIREGUARD_TRADEWAR }}
        run: |
          sudo mkdir -p /etc/wireguard/
          echo "$TradeWar_CONFIG" | sudo tee /etc/wireguard/wg0.conf > /dev/null
          sudo chmod 600 /etc/wireguard/wg0.conf

          for i in {1..5}; do
              sudo wg-quick up wg0
              sleep 1 
              if sudo wg show wg0 >/dev/null 2>&1; then
                  echo "VPN connected successfully on attempt $i"
                  break
              else
                  echo "VPN connection failed (attempt $i/5)"
                  sudo wg-quick down wg0 >/dev/null 2>&1
                  [ $i -lt 5 ] && sleep 1
              fi
          done

          if ! sudo wg show wg0 >/dev/null 2>&1; then
              echo "::error::VPN failed to connect after 5 attempts"
              exit 1
          fi

      - name: Download and Process Video
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        continue-on-error: true
        run: |
          mkdir -p output
          URL="${{ steps.feed-parser.outputs.url }}"
          
          yt-dlp -i --no-progress \
            -S \"+res:1080,+vcodec:av01\" --windows-filenames \
            -o \"output/%(title).170B [%(id)s] (%(resolution)s).%(ext)s\" \
            --live-from-start --embed-metadata ${URL}

      - name: VPN Cleanup
        if: ${{ always() && steps.feed-parser.outputs.should_process == 'true' }}
        run: |
          sudo wg-quick down wg0 || true

      - name: Upload Artifact
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: downloaded-video
          path: output
          compression-level: 1
          if-no-files-found: error

      - name: Upload Files to Cloud Storage
        if: ${{ steps.feed-parser.outputs.should_process == 'true' }}
        run: |
          UPLOAD_URL="https://upload.gofile.io/uploadfile"
          UPLOAD_LINKS=""
          guest_token=""
          folder_id=""

          upload_file() {
            local file=$1
            shift
            local extra_args=("$@")

            RESPONSE=$(curl -s -X POST -F "file=@\"$file\"" "${extra_args[@]}" "$UPLOAD_URL")
            STATUS=$(echo "$RESPONSE" | jq -r '.status')
            if [ "$STATUS" != "ok" ]; then
              ERROR=$(echo "$RESPONSE" | jq -r '.data // .status')
              echo "::error::Upload failed for $file: $ERROR"
              exit 1
            fi
            echo "$RESPONSE"
          }

          for file in output/*; do
            echo "Uploading $(basename "$file")..."
            extra_args=()
            if [ -n "$guest_token" ] && [ "$guest_token" != "null" ] && 
               [ -n "$folder_id" ] && [ "$folder_id" != "null" ]; then
              echo "::add-mask::$guest_token"
              echo "::add-mask::$folder_id"
              extra_args=(-H "Authorization: Bearer $guest_token" -F "folderId=$folder_id")
            fi

            RESPONSE=$(upload_file "$file" "${extra_args[@]}")

            if [ -z "$guest_token" ]; then
              guest_token=$(echo "$RESPONSE" | jq -r '.data.guestToken')
              echo "::add-mask::$guest_token"
            fi
            if [ -z "$folder_id" ]; then
              folder_id=$(echo "$RESPONSE" | jq -r '.data.parentFolder')
              echo "::add-mask::$folder_id"
            fi

            LINK=$(echo "$RESPONSE" | jq -r '.data.downloadPage')
            UPLOAD_LINKS+="- [$(basename "$file")]($LINK)\n"
          done

          FILE_COUNT=$(echo -e "$UPLOAD_LINKS" | grep -c '^-')
          SUMMARY="### 📁 Upload Results\n**Files uploaded:** $FILE_COUNT"

          # Append the upload summary to GitHub Step Summary
          echo -e "$SUMMARY\n\n$UPLOAD_LINKS" >> $GITHUB_STEP_SUMMARY
          echo "links=$(echo -e "$UPLOAD_LINKS" | base64 -w 0)" >> $GITHUB_OUTPUT
